{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5673760-2d3b-4530-9f08-9a8717e37ee6",
   "metadata": {},
   "source": [
    "# Practicum: Let's Play around with Classical Hopfield Networks\n",
    "In this practicum, we are going to explore encoding and retrieving multiple __binary__ patterns using classical Hopfield Networks. In the lecture example, we considered only a single memory. In this practicum problem, we expand the number of memories that we encode in the network. Does the retrieval algorithm presented in `L15a` lecture work for multiple memories? (we'll see!)\n",
    "\n",
    "> __Learning Objectives:__\n",
    "> \n",
    "> By the end of this practicum, you should be able to:\n",
    "> * **Encode multiple patterns into a Hopfield network using Hebbian learning**: Apply the Hebbian learning rule to compute network weights from multiple binary patterns and understand how the weights encode pattern information as an outer product sum.\n",
    "> * **Retrieve corrupted patterns from a Hopfield network**: Implement the asynchronous update algorithm to recover stored patterns from noisy initial states by iteratively minimizing network energy.\n",
    "> * **Analyze Hopfield network retrieval performance**: Evaluate how retrieval accuracy changes as the number of encoded patterns approaches the theoretical storage limit and observe the impact of pattern interference on convergence.\n",
    "\n",
    "Let's get started!\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468895f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Background: Classical Hopfield Networks\n",
    "A classical Hopfield network is a fully connected, undirected graph consisting of $N$ nodes, where each node has a binary state $s = \\pm 1$. Each node is connected to every other node, but not to itself. The connection weights between nodes $i$ and $j$, denoted $w_{ij} \\in \\mathbf{W}$, are determined using a **Hebbian learning rule**.\n",
    "\n",
    "> __Hebbian learning__\n",
    ">\n",
    "> * __Hebbian learning__, The [Hebbian learning rule](https://en.wikipedia.org/wiki/Hebbian_theory), proposed by [Donald Hebb in 1949](https://en.wikipedia.org/wiki/Donald_O._Hebb), says that synaptic connections between neurons are strengthened when they activate (fire) simultaneously, forming the biological basis for __associative learning__. This \"fire together, wire together\" principle underpins unsupervised learning in neural networks, linking co-active nodes to enable pattern storage and recall.\n",
    "> * __Different?__ Unlike the previous examples of learning, e.g., logistic regression, or any of the online learning approaches that we looked at previously, the parameters (weights) in a [Hopfield network](https://en.wikipedia.org/wiki/Hopfield_network) are entirely specified by the memories we want to encode. Thus, we do not need to search for weights or learn them by experimenting with the world. Instead, we can directly compute the weights from the memories we want to encode.\n",
    "> * __Recurrent?__ a Hopfield network is a special type of [recurrent neural network](https://en.wikipedia.org/wiki/Recurrent_neural_network) in which recurrence is used to settle into a stable pattern iteratively. It is considered recurrent because its units are symmetrically and recurrently connected, allowing the network to evolve toward an energy minimum over time.\n",
    "> \n",
    "> The Hebbian learning rule uses only local computations without explicit training iterations, providing a biological basis for memory encoding that operates without specialized hardware or extended optimization cycles.\n",
    "\n",
    "\n",
    "### Encoding memories into a Hopfield network\n",
    "Suppose we wish our network to memorize $K$-images, where each image is an $n\\times{n}$ collection of black and white pixels represented as a vector $\\mathbf{s}_{i}\\in\\left\\{-1,1\\right\\}^{n^2}$. We encode the image using the following rule: if the pixel is white, we set the memory value to `1`, and if the pixel is black, we set the memory value to `-1`. Then, the weights that encode these $K$-images are given by:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\mathbf{W} = \\frac{1}{K}\\cdot\\sum_{i=1}^{K}\\mathbf{s}_{i}\\otimes\\mathbf{s}_{i}^{\\top}\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $\\mathbf{s}_{i}$ denotes the state (pixels) of the image we want to memorize, and $\\otimes$ denotes the outer product. Thus, the weights are like an average of all of our memories!\n",
    "\n",
    "What about the bias term $b_{i}$? In this practicum, we will set the bias term to zero, i.e., $b_{i} = 0$ for all neurons $i$. This simplifies the network and focuses on the core dynamics of memory storage and retrieval.\n",
    "\n",
    "> __How big can $K$ be?__: The maximum theoretical storage limit $K_{\\text{max}}$ of a classical Hopfield network, using the standard Hebbian learning rule, is approximately $K_{max}\\sim{0.138}{N}$, where $N$ is the number of neurons in the network. Thus, the network can reliably store about 14% of its size in patterns before retrieval errors become significant due to interference between stored patterns.\n",
    "\n",
    "Suppose we've encoded $K$ images and want to retrieve one of them. This seems magical. How does it work? \n",
    "\n",
    "### Algorithm: Memory retrieval\n",
    "Each memory in a Hopfield network is encoded as a _local minimum_ of a global energy function. Thus, during memory retrieval, when we supply a random state vector $\\hat{\\mathbf{s}}$, we will recover the _closest_ memory encoded in the network to where we start.\n",
    "The overall energy of the network is given by:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "E(\\mathbf{s}) = -\\frac{1}{2}\\,\\sum_{ij}w_{ij}s_{i}s_{j} - \\sum_{i}b_{i}s_{i}\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $w_{ij}\\in\\mathbf{W}$ are the weights of the network, and $b_{i}$ is a bias term. The bias term is used to control the activation of the neurons in the network. The bias term is usually set to zero, but it can be used to control the activation threshold of the neurons in the network.\n",
    "\n",
    "Let's outline some pseudocode for the memory retrieval algorithm.\n",
    "\n",
    "__Initialize__: Compute the weights $w_{ij}\\in\\mathbf{W}$ using the Hebbian learning rule. Initialize the network with a random state $\\mathbf{s}$.  Set $\\texttt{converged}\\gets\\texttt{false}$, the iteration counter $t\\gets{1}$, maximum iterations $\\texttt{maxiter} = 10N$ (where $N$ is the number of neurons), and patience parameter $\\texttt{patience}$.\n",
    "\n",
    "> **Patience Parameter?** \n",
    "> \n",
    "> The patience parameter is used to determine how many consecutive identical states are required to declare convergence. A patience parameter is a practical heuristic that balances convergence detection with computational efficiency. Classical Hopfield networks can occasionally get stuck in short oscillation cycles (e.g., alternating between a few states). Requiring a fixed number of consecutive identical states ensures the network has truly converged to a stable attractor rather than just pausing briefly, or terminating prematurely. \n",
    "\n",
    "__Track__: Initialize a queue $\\texttt{S}$ to store the last $\\texttt{patience}$ state vectors.\n",
    "\n",
    "While not $\\texttt{converged}$ __do__:\n",
    "1. Store the current state: $\\mathbf{s}_{\\text{old}} \\gets \\mathbf{s}$.\n",
    "2. **Asynchronous update**: Choose a random node $i$ and compute a new state $s_{i}^{\\prime}$ using the update rule: $s_{i}^{\\prime} \\leftarrow \\texttt{sign}\\left(\\sum_{j}w_{ij}s_{j}-b_{i}\\right)$, where $\\texttt{sign}(\\cdot)$ is the sign function and $b_{i}$ is a bias (threshold) parameter.\n",
    "3. Update the network state: $\\mathbf{s} \\leftarrow \\mathbf{s}^{\\prime}$ (only neuron $i$ changes).\n",
    "4. Add current state to history: $\\texttt{S}\\gets\\texttt{S} \\cup \\{\\mathbf{s}\\}$.\n",
    "5. **Check for convergence**: There are several criteria that we can use to stop the iteration and determine if the network has converged:\n",
    "   - **State stability**: If the state history $\\texttt{S}$ contains $\\texttt{patience}$ states and all states in the history are identical (Hamming distance = 0 between all consecutive pairs), then set $\\texttt{converged}\\gets\\texttt{true}$.\n",
    "   - **Memory retrieval**: Alternatively, if the current state $\\mathbf{s}$ exactly matches any stored memory pattern $\\mathbf{s}_k$ (Hamming distance = 0), then set $\\texttt{converged}\\gets\\texttt{true}$.\n",
    "   - **Energy true minimum**: If the energy $E(\\mathbf{s})$ equals or is lower than the __true minimum__, then set $\\texttt{converged}\\gets\\texttt{true}$. Notify that true minimum energy reached.\n",
    "   - __Max iterations__: If $t \\geq \\texttt{maxiter}$, set $\\texttt{converged}\\gets\\texttt{true}$. Notify that maximum iterations reached without convergence.\n",
    "6. If the length of the state history $\\texttt{S}$ queue exceeds $\\texttt{patience}$ length, remove the oldest state.\n",
    "7. Update iteration counter: $t \\leftarrow t + 1$.\n",
    "\n",
    "> **Hamming Distance**: The Hamming distance between two binary vectors $\\mathbf{a}$ and $\\mathbf{b}$ is defined as $H(\\mathbf{a}, \\mathbf{b}) = \\sum_{i=1}^{N} \\mathbb{I}[a_i \\neq b_i]$, where $\\mathbb{I}[\\cdot]$ is the indicator function. For convergence, we check if $H(\\mathbf{s}_{\\text{current}}, \\mathbf{s}_{\\text{previous}}) = 0$, meaning the states are identical.\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b0615a",
   "metadata": {},
   "source": [
    "## Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. \n",
    "\n",
    "> The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414aa20a",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: Oppps! No methods defined in src/Types.jl. What should you do here?\nin expression starting at /Users/wangyiyun/Documents/practicum-5800-f2025-sabrina803/src/Types.jl:1\nin expression starting at /Users/wangyiyun/Documents/practicum-5800-f2025-sabrina803/Include.jl:29",
     "output_type": "error",
     "traceback": [
      "LoadError: Oppps! No methods defined in src/Types.jl. What should you do here?\n",
      "in expression starting at /Users/wangyiyun/Documents/practicum-5800-f2025-sabrina803/src/Types.jl:1\n",
      "in expression starting at /Users/wangyiyun/Documents/practicum-5800-f2025-sabrina803/Include.jl:29\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Documents/practicum-5800-f2025-sabrina803/src/Types.jl:1"
     ]
    }
   ],
   "source": [
    "include(\"Include.jl\"); # load a bunch of libs, including the ones we need to work with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fc8fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extension(file::String) = file[findlast(==('.'), file)+1:end]; # helper function to get the file extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd786069",
   "metadata": {},
   "source": [
    "For the practicum problem, all data and code is locally defined in the `data/` and `src/` folders. For additional information on functions and types used in this material, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/) or the documentation for any external packages used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b64811",
   "metadata": {},
   "source": [
    "### Load the uncorrelated image dataset\n",
    "In this example, we use a Hopfield network to memorize and retrieve image patterns from [the MNIST handwritten digits dataset](https://en.wikipedia.org/wiki/MNIST_database). We will encode selected digit images into the network weights and then test whether the network can recover each image from a corrupted initial state.\n",
    "\n",
    "Let's first set some constants that define the problem size and dataset parameters. The comment next to each constant describes its purpose, units, and values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09a8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_training_examples = 30; # how many training examples of *each* number to include from the library\n",
    "number_digit_array = range(0,length=10,step=1) |> collect; # numbers 0 ... 9\n",
    "number_of_rows = 28; # number of rows in the image\n",
    "number_of_cols = 28; # number of cols in the image\n",
    "number_of_pixels = number_of_rows*number_of_cols; # how many pixels do we have in the image?\n",
    "number_of_images_to_memorize = 10; # number of images that we want to encode. This is roughly 9% of the theoretical capacity (Kmax ≈ 108), well below the 14% limit to ensure reliable retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acadc29",
   "metadata": {},
   "source": [
    "The code block below loads all training images from the dataset directory and stores them in the `training_image_array::Array{Gray{N0f8},3}` variable as a 3D array where images are indexed along the third dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817ba7cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "training_image_array = let\n",
    "    \n",
    "    # initialize -\n",
    "    training_image_dictionary = Dict{Int64, Array{Gray{N0f8},3}}();\n",
    "    files = readdir(joinpath(_PATH_TO_IMAGES));\n",
    "    number_of_files = length(files); \n",
    "    image_digit_array = Array{Gray{N0f8},3}(undef, number_of_rows, number_of_cols, number_of_training_examples);\n",
    "\n",
    "    for i ∈ 1:(number_of_training_examples-1)    \n",
    "        filename = files[i];\n",
    "        image_digit_array[:,:,i] = joinpath(_PATH_TO_IMAGES, filename) |> x-> FileIO.load(x);\n",
    "    end\n",
    "    image_digit_array;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e30164",
   "metadata": {},
   "source": [
    "Next, we convert the images from matrix format to vector format for network processing.\n",
    "\n",
    "> * __Why vectorize?__ Each $n\\times n$ image array containing grayscale pixel values is flattened into a vector of length $n^2$ by concatenating pixel values in row-major order. This vector representation is required for the Hopfield network, which operates on flattened input patterns.\n",
    "> * __Floating-point precision:__ Most neural network libraries use `Float32` (single precision) rather than `Float64` (double precision) to reduce memory requirements and improve computational speed. This is especially important for large-scale networks and when using specialized hardware such as [Graphical Processing Units (GPUs)](https://www.nvidia.com/en-us/data-center/h100/).\n",
    "\n",
    "The vectorized training data will be stored in the `training_image_dataset::Vector{Vector{Float32}}` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69261c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_dataset = let\n",
    "\n",
    "    # initialize\n",
    "    training_image_dataset = Vector{Vector{Float32}}();\n",
    "    X = training_image_array; # shorthand\n",
    "    \n",
    "    for t ∈ 1:number_of_training_examples\n",
    "        D = Array{Float32,1}(undef, number_of_pixels);\n",
    "    \n",
    "        linearindex = 1;\n",
    "        for row ∈ 1:number_of_rows\n",
    "            for col ∈ 1:number_of_cols\n",
    "                D[linearindex] = X[row,col,t] |> x-> convert(Float32,x);\n",
    "                linearindex+=1;\n",
    "            end\n",
    "        end\n",
    "        push!(training_image_dataset,D);\n",
    "    end\n",
    "    training_image_dataset\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c52c7",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0826a",
   "metadata": {},
   "source": [
    "## Task 1: Learn the Weights of the Network\n",
    "In this task, we'll learn the weights of the Hopfield network using the training data. A [Hopfield network](https://en.wikipedia.org/wiki/Hopfield_network) uses a special [Hebbian learning rule](https://arxiv.org/pdf/2010.01472), where the weights $w_{ij}\\in\\mathbf{W}$ are _encoded_ by the image (or memory) the network is trying to learn. How many images can we encode? Let's find out!\n",
    "\n",
    "> * __How big is $K_{\\text{max}}$?__: The maximum theoretical storage limit $K_{\\text{max}}$ (the maximum number of possible images that can be stored) of a classical Hopfield network, using the standard Hebbian learning rule, is approximately $K_{max}\\sim{0.138}{N}$, where $N$ is the number of neurons (nodes) in the network. Thus, the network can reliably store about 14% of its size in patterns before retrieval errors become significant due to interference between stored patterns.\n",
    "> * __Reference__ The paper exploring this theoretical limit: [Folli V, Leonetti M, Ruocco G. On the Maximum Storage Capacity of the Hopfield Model. Front Comput Neurosci. 2017 Jan 10;10:144. doi: 10.3389/fncom.2016.00144. PMID: 28119595; PMCID: PMC5222833.](https://pubmed.ncbi.nlm.nih.gov/28119595/)\n",
    "\n",
    "Let's store the maximum number of images that we can encode in the `Kmax::Int` variable. Let's assume that we have one node for each pixel in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ae15b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Kmax = 0.138*number_of_pixels |> x-> round(x, RoundDown) # max number of images the network can memorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc98c8",
   "metadata": {},
   "source": [
    "Next, let's generate a random set of image indexes that we encode into the model. We'll store this collection in the `image_index_set_to_encode::Set{Int64}` variable.\n",
    "> __How do we build this set?__ We specify the number of images that we want in the `number_of_images_to_memorize::Int` variable; then we iterate using [a `while-loop`](https://docs.julialang.org/en/v1/base/base/#while) until we generate the required number of indexes _randomly_. We stop the loop once we hit our target number. Fun data structure question: why do we use [a Julia `Set`](https://docs.julialang.org/en/v1/base/collections/#Base.Set) instead of an array?\n",
    "\n",
    "The code block below shows how we generate a random set of image indices to encode into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7473649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index_set_to_encode = let\n",
    "\n",
    "    # how many images do we want to encode?\n",
    "    number_of_possible_images = length(training_image_dataset);\n",
    "    image_index_set_to_encode = Set{Int64}();\n",
    "\n",
    "    is_ok_to_stop = false; # iteration flag\n",
    "    while (is_ok_to_stop == false)\n",
    "        \n",
    "        # generate a random index -\n",
    "        j = rand(1:number_of_possible_images);\n",
    "        push!(image_index_set_to_encode, j); # add to the image set -\n",
    "\n",
    "        # check: have we hit the number that we want?\n",
    "        if (length(image_index_set_to_encode) ≥ number_of_images_to_memorize)\n",
    "            is_ok_to_stop = true;\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # return \n",
    "    image_index_set_to_encode;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0ae0e-3cbe-4664-a5af-421ca8496c8b",
   "metadata": {},
   "source": [
    "Let's visualize the images we randomly selected to memorize. These will be the \"true\" images that our network will attempt to recover when given a corrupted noisy version as input.\n",
    "\n",
    "> __How does the decoding work?__ Each image is stored in the `training_image_dataset::Vector{Vector{Float32}}` as a flattened vector of grayscale pixel values. We convert this vector representation back to the original $n \\times n$ binary format for visualization using the `decode(...)` function. The code block below iterates through each selected image index and displays the corresponding binary pattern.\n",
    "\n",
    "The code block below displays the memorized images that the network will learn to retrieve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab441280-7d8d-4e4e-b0d3-45163fbb3d12",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `decode` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in ChunkCodecCore.\n    - Also exported by ChunkCodecLibZlib (loaded but not imported in Main).\n    - Also exported by ChunkCodecLibZstd (loaded but not imported in Main).",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `decode` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "Hint: a global variable of this name also exists in ChunkCodecCore.\n",
      "    - Also exported by ChunkCodecLibZlib (loaded but not imported in Main).\n",
      "    - Also exported by ChunkCodecLibZstd (loaded but not imported in Main).\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X24sZmlsZQ==.jl:16"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    index_vector = image_index_set_to_encode |> collect |> sort; # we'll process this in this order \n",
    "    for example_image_index ∈ index_vector\n",
    "    \n",
    "        ŝₖ = training_image_dataset[example_image_index]; # raw state *not* scaled to -1,1\n",
    "        s = Array{Int32,1}(undef, number_of_pixels); # initialize some space\n",
    "        for i ∈ 1:number_of_pixels\n",
    "            pixel =  ŝₖ[i] |> x-> round(Int,x); # why do we have to round here?\n",
    "            if pixel == 0.0\n",
    "                s[i] = -1\n",
    "            else\n",
    "                s[i] = 1;\n",
    "            end\n",
    "        end\n",
    "        display(decode(s) |> img -> Gray.(img))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f502a66",
   "metadata": {},
   "source": [
    "### Encode a Hopfield model\n",
    "Now that we have the training images let's encode the model. We'll compute the weights and the bias term and store them [in an instance of the `MyClassicalHopfieldNetworkModel` type](src/Types.jl). The weights are stored in the `W` field, and the bias term is stored in the `b` field. \n",
    "\n",
    "> __How do we build this model__? We build the model (and estimate the weight matrix and bias vector) using [the `build(...)` method](src/Factory.jl). This method takes the type of thing we want to construct, namely [a `MyClassicalHopfieldNetworkModel` instance](src/Types.jl), and the memories we want to encode. The (vectorized) memories are stored in the columns of an array. The [`build(...)` method](src/Compute.jl) returns a model instance with the `W` and `b` fields populated.\n",
    "\n",
    "Let's store the encoded model in the `model::MyClassicalHopfieldNetworkModel` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08e882f3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `build` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in Pkg.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `build` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "Hint: a global variable of this name also exists in Pkg.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X26sZmlsZQ==.jl:26"
     ]
    }
   ],
   "source": [
    "model = let\n",
    "\n",
    "    # initialize -\n",
    "    number_of_images_to_learn = length(image_index_set_to_encode);\n",
    "    linearimagecollection = Array{Int32,2}(undef, number_of_pixels, number_of_images_to_learn); # images on columns\n",
    "    \n",
    "    # turn our set into a sorted vector -\n",
    "    index_vector = image_index_set_to_encode |> collect |> sort; # we'll process this in this order \n",
    "    for k ∈ eachindex(index_vector)\n",
    "        \n",
    "        j = index_vector[k];\n",
    "        ŝₖ = training_image_dataset[j]; # raw state *not* scaled to -1,1\n",
    "\n",
    "        # fill the columns of the array -\n",
    "        for i ∈ 1:number_of_pixels\n",
    "            pixel =  ŝₖ[i] |> x-> round(Int,x);\n",
    "            if pixel == 0.0 # hmmm\n",
    "                linearimagecollection[i,k] = -1;\n",
    "            else\n",
    "                linearimagecollection[i,k] = 1;\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # build the model using the encode function -\n",
    "    model = build(MyClassicalHopfieldNetworkModel, (\n",
    "        memories = linearimagecollection,\n",
    "    ));\n",
    "\n",
    "    # return -\n",
    "    model\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6b180e",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b58401",
   "metadata": {},
   "source": [
    "## Task 2: Retrieve a memory from the network\n",
    "In this task, we will retrieve a memory from the Hopfield network starting from a random state vector $\\mathbf{s}_{\\circ}$. Let's start by specifying which of the images we expect to recover in the `imageindextorecover::Int` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ec6f08a-f892-48ad-bf49-3ba7d0f35dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageindextorecover = 1; # which element of the index vector will we choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e670b14a",
   "metadata": {},
   "source": [
    "For comparison purposes later, what is the energy of the true image? Let's look it up from the model's energy dictionary and store it in the `true_image_energy::Float32` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f82ef670",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `model` not defined in `Main`\nSuggestion: add an appropriate import or assignment. This global was declared but not assigned.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `model` not defined in `Main`\n",
      "Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X34sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "true_image_energy = model.energy[imageindextorecover]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c703bda-8ad5-4b7b-8340-f7146318f74e",
   "metadata": {},
   "source": [
    "Next, we'll build a corrupted initial condition vector $\\mathbf{s}_{\\circ}$ based on a selected memorized image. This vector will serve as the starting point for the memory recovery algorithm. We initialize the state vector by converting each pixel to the binary scale $\\{-1, 1\\}$ and then systematically corrupt a fraction of the pixels to simulate noisy input.\n",
    "\n",
    "> __The $\\theta$ corruption parameter:__ The parameter $\\theta \\in [0,1]$ controls the fraction of pixels we preserve from the original image. Specifically, we keep the first $\\theta\\cdot{N}$ pixels from the correct image and set the remaining $(1-\\theta)\\cdot{N}$ pixels to $-1$, simulating damage or noise in the input. For example, if $\\theta = 0.5$, we preserve 50% of the original pixel values and corrupt the remaining 50%, creating a noisy version of the true image that the network must restore.\n",
    "\n",
    "Let's compute the corrupted initial condition vector `sₒ::Array{Int32,1}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a993ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "sₒ = let\n",
    "\n",
    "    # initialize -\n",
    "    index_vector = image_index_set_to_encode |> collect |> sort; # we'll process this in this order\n",
    "    index_of_image_to_encode = index_vector[imageindextorecover]; # -or- choose random\n",
    "    ŝₖ = training_image_dataset[index_of_image_to_encode]; # raw state *not* scaled to -1,1\n",
    "    sₒ = Array{Int32,1}(undef, number_of_pixels); # initialize some space\n",
    "    θ = 0.68; # fraction of pixels that we want to keep correct. This means ~32% corruption, providing a challenging but not impossible recovery task\n",
    "\n",
    "    # let's build the corrupted initial condition -\n",
    "    for i ∈ 1:number_of_pixels\n",
    "        pixel =  ŝₖ[i] |> x-> round(Int,x); # We have some gray-scale values in the original vector, need to round\n",
    "        if pixel == 0.0\n",
    "            sₒ[i] = -1;\n",
    "        else\n",
    "            sₒ[i] = 1;\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # # cut 1 - θ fraction of the pixels, replacewith - 1\n",
    "    number_of_pixels_to_corrupt = round(Int, (1 - θ)*number_of_pixels);\n",
    "    start =(number_of_pixels - number_of_pixels_to_corrupt) + 1;\n",
    "    for i ∈ start:number_of_pixels\n",
    "        sₒ[i] = -1;\n",
    "    end\n",
    "\n",
    "    sₒ # return\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3b03f",
   "metadata": {},
   "source": [
    "What does the initial state vector $\\mathbf{s}_{\\circ}$ look like (this should be a corrupted version of the `imageindextorecover::Int` image):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa316aea",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `decode` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in ChunkCodecCore.\n    - Also exported by ChunkCodecLibZlib (loaded but not imported in Main).\n    - Also exported by ChunkCodecLibZstd (loaded but not imported in Main).",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `decode` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "Hint: a global variable of this name also exists in ChunkCodecCore.\n",
      "    - Also exported by ChunkCodecLibZlib (loaded but not imported in Main).\n",
      "    - Also exported by ChunkCodecLibZstd (loaded but not imported in Main).\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X41sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "decode(sₒ) |> img -> Gray.(img) # corrupted true image. This is what we give the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16530208",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314bacb1",
   "metadata": {},
   "source": [
    "### Run the recovery algorithm\n",
    "Now that we have a corrupted initial state $\\mathbf{s}_{\\circ}$, can the network recover the original image?\n",
    "\n",
    "> __Expected behavior:__ The asynchronous update algorithm iteratively minimizes the network energy by randomly selecting neurons and updating their states based on the activation function. At each step, we record the network state and compute its energy. The algorithm should converge toward the memorized pattern by finding a state that corresponds to a local energy minimum. We expect the energy to generally decrease (or stabilize) as the network evolves from the noisy initial state toward a stored memory pattern.\n",
    "\n",
    "The recovery algorithm has been implemented in [the `recover(...)` method](src/Compute.jl). This method accepts:\n",
    "- `model::MyClassicalHopfieldNetworkModel`: The encoded Hopfield network with learned weights\n",
    "- `sₒ::Array{Int32,1}`: The corrupted initial state vector\n",
    "- `true_image_energy::Float32`: The energy of the target memorized pattern (for reference)\n",
    "- `maxiterations::Int64`: Maximum number of update steps to perform (optional: default is `1000`)\n",
    "- `patience::Union{Int,Nothing}`: Number of consecutive identical states required to declare convergence (optional: default is `5` or greater)\n",
    "- `miniterations_before_convergence::Union{Int,Nothing}`: minimum updates to run before checking convergence. If `nothing`, defaults to `patience`.\n",
    "\n",
    "The method returns:\n",
    "- `frames::Dict{Int64, Array{Int32,1}}`: A dictionary mapping iteration index to the network state at that iteration\n",
    "- `energydictionary::Dict{Int64, Float32}`: A dictionary mapping iteration index to the network energy at that iteration\n",
    "\n",
    "Call [the `recover(...)` method](src/Compute.jl) below to perform memory retrieval from the corrupted initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94f036d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `recover` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `recover` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X44sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "frames, energydictionary = recover(model, sₒ, true_image_energy, maxiterations=25*number_of_pixels, \n",
    "    patience = number_of_pixels);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c54da-c421-4608-9ea1-31cab6af1ec2",
   "metadata": {},
   "source": [
    "Which image does the model recover? The code block below displays the true image (top), the corrupted initial image (middle), and the recovered image (bottom).\n",
    "\n",
    "> __Check:__ \n",
    "> \n",
    "> To evaluate the quality of the recovered image, we can compute the Hamming distance between the recovered state and the true image. The Hamming distance quantifies the number of differing pixels, providing a measure of retrieval accuracy. A lower Hamming distance indicates a closer match to the original image. If the Hamming distance is zero, it means the recovered image exactly matches the true image.\n",
    "> \n",
    "> We check if the Hamming distance between the recovered image and the true image is less than the Hamming distance between the corrupted image and the true image. If it is, no error is thrown; otherwise, an error is raised indicating that the recovery was unsuccessful.\n",
    "\n",
    "So what do we get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db8fc240",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `decode` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in ChunkCodecCore.\n    - Also exported by ChunkCodecLibZlib (loaded but not imported in Main).\n    - Also exported by ChunkCodecLibZstd (loaded but not imported in Main).",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `decode` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "Hint: a global variable of this name also exists in ChunkCodecCore.\n",
      "    - Also exported by ChunkCodecLibZlib (loaded but not imported in Main).\n",
      "    - Also exported by ChunkCodecLibZstd (loaded but not imported in Main).\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X46sZmlsZQ==.jl:18"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    # initialize -\n",
    "    index_vector = image_index_set_to_encode |> collect |> sort; # we'll process this in this order\n",
    "    my_index_of_image_to_encode = index_vector[imageindextorecover]; # -or- choose random\n",
    "\n",
    "    # true image -\n",
    "    ŝₖ = training_image_dataset[my_index_of_image_to_encode]; # raw state *not* scaled to -1,1\n",
    "    s₁ = Array{Int32,1}(undef, number_of_pixels); # initialize some space\n",
    "    for i ∈ 1:number_of_pixels\n",
    "        pixel =  ŝₖ[i] |> x-> round(Int,x); # why do we have to round here?\n",
    "        if pixel == 0.0\n",
    "            s₁[i] = -1\n",
    "        else\n",
    "            s₁[i] = 1;\n",
    "        end\n",
    "    end\n",
    "    true_image = decode(s₁); # this is the true image\n",
    "    initial_image = decode(sₒ); # initial corrupted image\n",
    "    \n",
    "    # recovered image -\n",
    "    ks = collect(keys(energydictionary))\n",
    "    best_key = argmin(k -> energydictionary[k], ks)\n",
    "    best_state = frames[best_key]\n",
    "    recovered_image = decode(best_state)\n",
    "\n",
    "    display(true_image |> img -> Gray.(img))\n",
    "    display(initial_image |> img -> Gray.(img))\n",
    "    display(recovered_image |> img -> Gray.(img))\n",
    "\n",
    "    println(\"Hamming (best vs true) = \", hamming(best_state, s₁))\n",
    "    println(\"Hamming (initial vs true) = \", hamming(sₒ, s₁))\n",
    "    println(\"Best energy = \", energydictionary[best_key])\n",
    "    println(\"True energy = \", true_image_energy)\n",
    "\n",
    "    # check: the hamming distance between the best and true should be less than that between the initial and true\n",
    "    @assert hamming(best_state, s₁) < hamming(sₒ, s₁) \"Error: Hamming distance check failed!\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a28d3b",
   "metadata": {},
   "source": [
    "Does the energy decrease as we flip the states in the network? Let's plot the values in the `energydictionary::Dict{Int64, Float32}` and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e22d8d8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `energydictionary` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `energydictionary` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X51sZmlsZQ==.jl:3"
     ]
    }
   ],
   "source": [
    "let\n",
    "    p = plot(bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent); \n",
    "    plot!(energydictionary, lw=3, c=:navy, label=\"\", xminorticks=true, yminorticks=true);\n",
    "   \n",
    "    # plot true energy line -\n",
    "    TEL = true_image_energy*ones(length(energydictionary));\n",
    "    plot!(TEL, lw=2, c=:red, label=\"True image energy\", ls=:dash);\n",
    "    xlabel!(\"Step index (AU)\", fontsize=18)\n",
    "    ylabel!(\"Network configuration energy (AU)\", fontsize=18)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df232c",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebadad46",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This practicum explores encoding and retrieving multiple binary patterns from classical Hopfield networks using Hebbian learning and energy-based optimization.\n",
    "\n",
    "> __Key Takeaways:__\n",
    "> \n",
    "> * **Hebbian learning for memory storage:** The network weights encode stored patterns through an outer product sum of memories, allowing direct computation of weights without iterative training. This biological learning mechanism enables unsupervised memory formation based on co-activation patterns.\n",
    "> * **Energy minimization for pattern recovery:** Memory retrieval operates by iteratively updating neuron states to minimize network energy, allowing the algorithm to recover stored patterns from corrupted or noisy initial conditions through local computations.\n",
    "> * **Storage capacity limits:** Classical Hopfield networks can reliably store approximately 14% of their neuron count in distinct patterns before interference between memories degrades retrieval performance. This fundamental capacity constraint reflects a trade-off between network size and memory density.\n",
    "\n",
    "Hopfield networks demonstrate how local learning rules and energy functions can implement associative memory, providing a foundation for understanding recurrent neural network dynamics and constrained optimization in neural systems.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd22d6c",
   "metadata": {},
   "source": [
    "## Tests\n",
    "The code block below shows how we implemented the tests and what we are testing. In these tests, we check values in your notebook and give feedback on which items are correct, missing, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7fbf2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1: Learn the Weights of the Network: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1m/Users/jeffreyvarner/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:22\u001b[22m\n",
      "  Test threw exception\u001b[39m\u001b[1m/Users/jeffreyvarner/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:22\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: size(model.W) == (number_of_pixels, number_of_pixels)\n",
      "  UndefVarError: `model` not defined in `Main`\n",
      "  Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "  Stacktrace:\n",
      "   [1] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:3\u001b[24m\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:17\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:22\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:677\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 1: Learn the Weights of the Network: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1m/Users/jeffreyvarner/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:23\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: model.W ≈ (model.W)'\n",
      "  UndefVarError: `model` not defined in `Main`\n",
      "  Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "  Stacktrace:\n",
      "   [1] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:3\u001b[24m\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:17\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:23\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:677\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 1: Learn the Weights of the Network: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1m/Users/jeffreyvarner/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:24\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: all(iszero, model.b)\n",
      "  UndefVarError: `model` not defined in `Main`\n",
      "  Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "  Stacktrace:\n",
      "   [1] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:3\u001b[24m\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:17\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:24\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:677\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [7] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:24\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 1: Learn the Weights of the Network: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1m/Users/jeffreyvarner/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:25\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: all(iszero, diag(model.W))\n",
      "  UndefVarError: `model` not defined in `Main`\n",
      "  Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "  Stacktrace:\n",
      "   [1] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:3\u001b[24m\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:17\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:25\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:677\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [7] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:25\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 1: Learn the Weights of the Network: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1m/Users/jeffreyvarner/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:26\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: length(model.energy) == number_of_images_to_memorize\n",
      "  UndefVarError: `model` not defined in `Main`\n",
      "  Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "  Stacktrace:\n",
      "   [1] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:3\u001b[24m\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:17\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:26\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:677\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 2: Retrieve a Memory from the Network: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1m/Users/jeffreyvarner/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:29\u001b[22m\n",
      "  Got exception outside of a @test\n",
      "  UndefVarError: `energydictionary` not defined in `Main`\n",
      "  Suggestion: check for spelling errors or missing imports.\n",
      "  Stacktrace:\n",
      "    [1] top-level scope\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:3\u001b[24m\u001b[39m\n",
      "    [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  Expression: size(model.W) == (number_of_pixels, number_of_pixels)\n",
      "  UndefVarError: `model` not defined in `Main`\n",
      "  Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "  Stacktrace:\n",
      "   [1] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:3\u001b[24m\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:17\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:22\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:677\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 1: Learn the Weights of the Network: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1m/Users/jeffreyvarner/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:23\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: model.W ≈ (model.W)'\n",
      "  UndefVarError: `model` not defined in `Main`\n",
      "  Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "  Stacktrace:\n",
      "   [1] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:3\u001b[24m\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:17\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:23\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:677\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 1: Learn the Weights of the Network: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1m/Users/jeffreyvarner/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:24\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: all(iszero, model.b)\n",
      "  UndefVarError: `model` not defined in `Main`\n",
      "  Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "  Stacktrace:\n",
      "   [1] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:3\u001b[24m\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:17\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:24\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:677\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [7] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:24\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 1: Learn the Weights of the Network: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1m/Users/jeffreyvarner/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:25\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: all(iszero, diag(model.W))\n",
      "  UndefVarError: `model` not defined in `Main`\n",
      "  Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "  Stacktrace:\n",
      "   [1] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:3\u001b[24m\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:17\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:25\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:677\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [7] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:25\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 1: Learn the Weights of the Network: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1m/Users/jeffreyvarner/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:26\u001b[22m\n",
      "  Test threw exception\n",
      "  Expression: length(model.energy) == number_of_images_to_memorize\n",
      "  UndefVarError: `model` not defined in `Main`\n",
      "  Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "  Stacktrace:\n",
      "   [1] top-level scope\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:3\u001b[24m\u001b[39m\n",
      "   [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:17\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:26\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "   [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m   @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:677\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "Task 2: Retrieve a Memory from the Network: \u001b[91m\u001b[1mError During Test\u001b[22m\u001b[39m at \u001b[39m\u001b[1m/Users/jeffreyvarner/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:29\u001b[22m\n",
      "  Got exception outside of a @test\n",
      "  UndefVarError: `energydictionary` not defined in `Main`\n",
      "  Suggestion: check for spelling errors or missing imports.\n",
      "  Stacktrace:\n",
      "    [1] top-level scope\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:3\u001b[24m\u001b[39m\n",
      "    [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "    [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:31\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "    [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "    [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:31\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "    [6] \u001b[0m\u001b[1meval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90me\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90mCore\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:489\u001b[24m\u001b[39m\n",
      "    [7] \u001b[0m\u001b[1minclude_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmapexpr\u001b[39m::\u001b[0mtypeof(REPL.softscope), \u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:2867\u001b[24m\u001b[39m\n",
      "    [8] \u001b[0m\u001b[1m(::VSCodeServer.var\"#notebook_runcell_request##0#notebook_runcell_request##1\"{VSCodeServer.NotebookRunCellArguments, String})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[35mVSCodeServer\u001b[39m \u001b[90m~/.vscode/extensions/julialang.language-julia-1.158.2/scripts/packages/VSCodeServer/src/\u001b[39m\u001b[90m\u001b[4mserve_notebook.jl:24\u001b[24m\u001b[39m\n",
      "    [9] \u001b[0m\u001b[1mwithpath\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mVSCodeServer.var\"#notebook_runcell_request##0#notebook_runcell_request##1\"\u001b[90m{VSCodeServer.NotebookRunCellArguments, String}\u001b[39m, \u001b[90mpath\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[35mVSCodeServer\u001b[39m \u001b[90m~/.vscode/extensions/julialang.language-julia-1.158.2/scripts/packages/VSCodeServer/src/\u001b[39m\u001b[90m\u001b[4mrepl.jl:278\u001b[24m\u001b[39m\n",
      "   [10] \u001b[0m\u001b[1mnotebook_runcell_request\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mconn\u001b[39m::\u001b[0mVSCodeServer.JSONRPC.JSONRPCEndpoint\u001b[90m{Base.PipeEndpoint, Base.PipeEndpoint, VSCodeServer.JSON.Serializations.StandardSerialization}\u001b[39m, \u001b[90mparams\u001b[39m::\u001b[0mVSCodeServer.NotebookRunCellArguments, \u001b[90mtoken\u001b[39m::\u001b[0mVSCodeServer.CancellationTokens.CancellationToken\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[35mVSCodeServer\u001b[39m \u001b[90m~/.vscode/extensions/julialang.language-julia-1.158.2/scripts/packages/VSCodeServer/src/\u001b[39m\u001b[90m\u001b[4mserve_notebook.jl:13\u001b[24m\u001b[39m\n",
      "   [11] \u001b[0m\u001b[1mdispatch_msg\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mVSCodeServer.JSONRPC.JSONRPCEndpoint\u001b[90m{Base.PipeEndpoint, Base.PipeEndpoint, VSCodeServer.JSON.Serializations.StandardSerialization}\u001b[39m, \u001b[90mdispatcher\u001b[39m::\u001b[0mVSCodeServer.JSONRPC.MsgDispatcher, \u001b[90mmsg\u001b[39m::\u001b[0mVSCodeServer.JSONRPC.Request\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[35mVSCodeServer.JSONRPC\u001b[39m \u001b[90m~/.vscode/extensions/julialang.language-julia-1.158.2/scripts/packages/JSONRPC/src/\u001b[39m\u001b[90m\u001b[4mtyped.jl:0\u001b[24m\u001b[39m\n",
      "   [12] \u001b[0m\u001b[1mserve_notebook\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpipename\u001b[39m::\u001b[0mString, \u001b[90mdebugger_pipename\u001b[39m::\u001b[0mString, \u001b[90moutputchannel_logger\u001b[39m::\u001b[0mBase.CoreLogging.SimpleLogger; \u001b[90merror_handler\u001b[39m::\u001b[0mvar\"#20#21\"\u001b[90m{String}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[35mVSCodeServer\u001b[39m \u001b[90m~/.vscode/extensions/julialang.language-julia-1.158.2/scripts/packages/VSCodeServer/src/\u001b[39m\u001b[90m\u001b[4mserve_notebook.jl:147\u001b[24m\u001b[39m\n",
      "   [13] top-level scope\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/.vscode/extensions/julialang.language-julia-1.158.2/scripts/notebook/\u001b[39m\u001b[90m\u001b[4mnotebook.jl:28\u001b[24m\u001b[39m\n",
      "   [14] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mBase.jl:306\u001b[24m\u001b[39m\n",
      "   [15] \u001b[0m\u001b[1mexec_options\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mopts\u001b[39m::\u001b[0mBase.JLOptions\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mclient.jl:317\u001b[24m\u001b[39m\n",
      "   [16] \u001b[0m\u001b[1m_start\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mclient.jl:550\u001b[24m\u001b[39m\n",
      "\u001b[0m\u001b[1mTest Summary:                                | \u001b[22m\n",
      "    [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:31\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "    [4] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/\u001b[39m\u001b[90m\u001b[4mTest.jl:1776\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "    [5] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/\u001b[39m\u001b[90m\u001b[4mjl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:31\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "    [6] \u001b[0m\u001b[1meval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90me\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90mCore\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mboot.jl:489\u001b[24m\u001b[39m\n",
      "    [7] \u001b[0m\u001b[1minclude_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmapexpr\u001b[39m::\u001b[0mtypeof(REPL.softscope), \u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:2867\u001b[24m\u001b[39m\n",
      "    [8] \u001b[0m\u001b[1m(::VSCodeServer.var\"#notebook_runcell_request##0#notebook_runcell_request##1\"{VSCodeServer.NotebookRunCellArguments, String})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[35mVSCodeServer\u001b[39m \u001b[90m~/.vscode/extensions/julialang.language-julia-1.158.2/scripts/packages/VSCodeServer/src/\u001b[39m\u001b[90m\u001b[4mserve_notebook.jl:24\u001b[24m\u001b[39m\n",
      "    [9] \u001b[0m\u001b[1mwithpath\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mVSCodeServer.var\"#notebook_runcell_request##0#notebook_runcell_request##1\"\u001b[90m{VSCodeServer.NotebookRunCellArguments, String}\u001b[39m, \u001b[90mpath\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[35mVSCodeServer\u001b[39m \u001b[90m~/.vscode/extensions/julialang.language-julia-1.158.2/scripts/packages/VSCodeServer/src/\u001b[39m\u001b[90m\u001b[4mrepl.jl:278\u001b[24m\u001b[39m\n",
      "   [10] \u001b[0m\u001b[1mnotebook_runcell_request\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mconn\u001b[39m::\u001b[0mVSCodeServer.JSONRPC.JSONRPCEndpoint\u001b[90m{Base.PipeEndpoint, Base.PipeEndpoint, VSCodeServer.JSON.Serializations.StandardSerialization}\u001b[39m, \u001b[90mparams\u001b[39m::\u001b[0mVSCodeServer.NotebookRunCellArguments, \u001b[90mtoken\u001b[39m::\u001b[0mVSCodeServer.CancellationTokens.CancellationToken\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[35mVSCodeServer\u001b[39m \u001b[90m~/.vscode/extensions/julialang.language-julia-1.158.2/scripts/packages/VSCodeServer/src/\u001b[39m\u001b[90m\u001b[4mserve_notebook.jl:13\u001b[24m\u001b[39m\n",
      "   [11] \u001b[0m\u001b[1mdispatch_msg\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mVSCodeServer.JSONRPC.JSONRPCEndpoint\u001b[90m{Base.PipeEndpoint, Base.PipeEndpoint, VSCodeServer.JSON.Serializations.StandardSerialization}\u001b[39m, \u001b[90mdispatcher\u001b[39m::\u001b[0mVSCodeServer.JSONRPC.MsgDispatcher, \u001b[90mmsg\u001b[39m::\u001b[0mVSCodeServer.JSONRPC.Request\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[35mVSCodeServer.JSONRPC\u001b[39m \u001b[90m~/.vscode/extensions/julialang.language-julia-1.158.2/scripts/packages/JSONRPC/src/\u001b[39m\u001b[90m\u001b[4mtyped.jl:0\u001b[24m\u001b[39m\n",
      "   [12] \u001b[0m\u001b[1mserve_notebook\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpipename\u001b[39m::\u001b[0mString, \u001b[90mdebugger_pipename\u001b[39m::\u001b[0mString, \u001b[90moutputchannel_logger\u001b[39m::\u001b[0mBase.CoreLogging.SimpleLogger; \u001b[90merror_handler\u001b[39m::\u001b[0mvar\"#20#21\"\u001b[90m{String}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[35mVSCodeServer\u001b[39m \u001b[90m~/.vscode/extensions/julialang.language-julia-1.158.2/scripts/packages/VSCodeServer/src/\u001b[39m\u001b[90m\u001b[4mserve_notebook.jl:147\u001b[24m\u001b[39m\n",
      "   [13] top-level scope\n",
      "  \u001b[90m    @\u001b[39m \u001b[90m~/.vscode/extensions/julialang.language-julia-1.158.2/scripts/notebook/\u001b[39m\u001b[90m\u001b[4mnotebook.jl:28\u001b[24m\u001b[39m\n",
      "   [14] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mBase.jl:306\u001b[24m\u001b[39m\n",
      "   [15] \u001b[0m\u001b[1mexec_options\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mopts\u001b[39m::\u001b[0mBase.JLOptions\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mclient.jl:317\u001b[24m\u001b[39m\n",
      "   [16] \u001b[0m\u001b[1m_start\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "  \u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mclient.jl:550\u001b[24m\u001b[39m\n",
      "\u001b[0m\u001b[1mTest Summary:                                | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[91m\u001b[1mError  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "CHEME 5800 Practicum Test Suite              | \u001b[32m   9  \u001b[39m\u001b[91m    6  \u001b[39m\u001b[36m   15  \u001b[39m\u001b[0m0.9s\n",
      "  Setup, Data, and Prerequisites             | \u001b[32m   6  \u001b[39m\u001b[91m       \u001b[39m\u001b[36m    6  \u001b[39m\u001b[0m0.3s\n",
      "  Task 1: Learn the Weights of the Network   | \u001b[32m   3  \u001b[39m\u001b[91m    5  \u001b[39m\u001b[36m    8  \u001b[39m\u001b[0m0.6s\n",
      "  Task 2: Retrieve a Memory from the Network | \u001b[32m      \u001b[39m\u001b[91m    1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m0.1s\n",
      "RNG of the outermost testset: \u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[91m\u001b[1mError  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "CHEME 5800 Practicum Test Suite              | \u001b[32m   9  \u001b[39m\u001b[91m    6  \u001b[39m\u001b[36m   15  \u001b[39m\u001b[0m0.9s\n",
      "  Setup, Data, and Prerequisites             | \u001b[32m   6  \u001b[39m\u001b[91m       \u001b[39m\u001b[36m    6  \u001b[39m\u001b[0m0.3s\n",
      "  Task 1: Learn the Weights of the Network   | \u001b[32m   3  \u001b[39m\u001b[91m    5  \u001b[39m\u001b[36m    8  \u001b[39m\u001b[0m0.6s\n",
      "  Task 2: Retrieve a Memory from the Network | \u001b[32m      \u001b[39m\u001b[91m    1  \u001b[39m\u001b[36m    1  \u001b[39m\u001b[0m0.1s\n",
      "RNG of the outermost testset: Random.Xoshiro(0xb439f495da04d736, 0x1f394e90243774cf, 0x0f63f057ba7b46fd, 0x9d304a804abe930f, 0xab2b9b7ef6499dfd)\n",
      "Random.Xoshiro(0xb439f495da04d736, 0x1f394e90243774cf, 0x0f63f057ba7b46fd, 0x9d304a804abe930f, 0xab2b9b7ef6499dfd)\n"
     ]
    },
    {
     "ename": "Test.TestSetException",
     "evalue": "Some tests did not pass: 9 passed, 0 failed, 6 errored, 0 broken.",
     "output_type": "error",
     "traceback": [
      "Some tests did not pass: 9 passed, 0 failed, 6 errored, 0 broken.\n",
      "\n",
      "Stacktrace:\n",
      " [1] finish(ts::Test.DefaultTestSet; print_results::Bool)\n",
      "   @ Test ~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/Test.jl:1270\n",
      " [2] finish(ts::Test.DefaultTestSet)\n",
      "   @ Test ~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/Test.jl:1245\n",
      " [3] top-level scope\n",
      "   @ ~/Desktop/julia_work/CHEME-5800-Fall-2025/CHEME-5800-PracticumProblem-Template-Fall-2025/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X54sZmlsZQ==.jl:3\n",
      " [4] macro expansion\n",
      "   @ ~/.julia/juliaup/julia-1.12.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.12/Test/src/Test.jl:1792 [inlined]"
     ]
    }
   ],
   "source": [
    "@testset verbose = true \"CHEME 5800 Practicum Test Suite\" begin\n",
    "\n",
    "    @testset \"Setup, Data, and Prerequisites\" begin\n",
    "        # Test basic constants\n",
    "        @test number_of_pixels == number_of_rows * number_of_cols\n",
    "        @test Kmax ≈ 0.138 * number_of_pixels atol=1  # approximate due to rounding\n",
    "        @test number_of_training_examples > 0\n",
    "        @test length(number_digit_array) > 0  # should have some digits\n",
    "        @test 0 < number_of_images_to_memorize <= Kmax\n",
    "        \n",
    "        # Test data loading\n",
    "        @test !isempty(training_image_dataset)\n",
    "    end\n",
    "\n",
    "    @testset \"Task 1: Learn the Weights of the Network\" begin\n",
    "        # Test image selection\n",
    "        @test length(image_index_set_to_encode) == number_of_images_to_memorize\n",
    "        @test isa(image_index_set_to_encode, Set)\n",
    "        @test all(1 .<= collect(image_index_set_to_encode) .<= length(training_image_dataset))\n",
    "        \n",
    "        # Test model properties\n",
    "        @test size(model.W) == (number_of_pixels, number_of_pixels)\n",
    "        @test model.W ≈ model.W'  # weight matrix should be symmetric\n",
    "        @test all(iszero, model.b)  # bias should be zero for classical Hopfield\n",
    "        @test all(iszero, diag(model.W))  # no self-connections\n",
    "        @test length(model.energy) == number_of_images_to_memorize\n",
    "    end\n",
    "\n",
    "    @testset \"Task 2: Retrieve a Memory from the Network\" begin\n",
    "        # Test recovery process\n",
    "        energy_keys = collect(keys(energydictionary))\n",
    "        initial_key = minimum(energy_keys)\n",
    "        initial_energy = energydictionary[initial_key]\n",
    "        final_energy = minimum(values(energydictionary))\n",
    "        @test final_energy <= initial_energy  # energy should not increase\n",
    "        @test length(frames) > 1  # should have run some iterations\n",
    "        @test keys(frames) == keys(energydictionary)  # same keys\n",
    "        \n",
    "        # Test best state - all states should be binary (from Hopfield network)\n",
    "        best_key = argmin(k -> energydictionary[k], energy_keys)\n",
    "        best_state = frames[best_key]\n",
    "        @test all(s -> abs(s) == 1, best_state)  # binary states (either +1 or -1)\n",
    "    end\n",
    "\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12.1",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
